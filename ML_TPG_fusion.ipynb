{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Istrate/80629_Project/blob/main/ML_TPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "smTmZO8eu5Uz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "import copy\r\n",
        "from random import seed\r\n",
        "from random import random\r\n",
        "import matplotlib.pyplot as plt  # import matplotlib for plotting and visualization\r\n",
        "import matplotlib\r\n",
        "import PIL\r\n",
        "from PIL import Image\r\n",
        "import PIL.Image\r\n",
        "import tensorflow as tf\r\n",
        "import pathlib\r\n",
        "import os\r\n",
        "import re\r\n",
        "import gc\r\n",
        "import sklearn\r\n",
        "from tensorflow.keras import layers\r\n",
        "from sklearn.utils import class_weight\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras import callbacks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------------\r\n",
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Train Validation TEST and survey\r\n",
        "path_train = pathlib.Path(r\"C:\\Users\\istra\\Google Drive\\Cours HEC\\Maitrise\\Semestre 2\\Machine_Learning\\TP GROUPE\\book_covers_final\\train\")\r\n",
        "path_valid = pathlib.Path(r\"C:\\Users\\istra\\Google Drive\\Cours HEC\\Maitrise\\Semestre 2\\Machine_Learning\\TP GROUPE\\book_covers_final\\valid\")\r\n",
        "path_test = pathlib.Path(r\"C:\\Users\\istra\\Google Drive\\Cours HEC\\Maitrise\\Semestre 2\\Machine_Learning\\TP GROUPE\\book_covers_final\\test\")\r\n",
        "path_survey = pathlib.Path(r\"C:\\Users\\istra\\Google Drive\\Cours HEC\\Maitrise\\Semestre 2\\Machine_Learning\\TP GROUPE\\book_covers_final\\survey\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqpsrIvlGB6H"
      },
      "source": [
        "Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading NLP Model 1\r\n",
        "NLP_model_1 = keras.models.load_model(\"NLP_LSTM1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading NLP Model \r\n",
        "NLP_model_2 = keras.models.load_model(\"NLP_LSTM1_nw.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading Resnet Model 1\r\n",
        "import tensorflow_hub as hub\r\n",
        "CNN_model_1 = keras.models.load_model(\"resnet_nd_15.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading VGG Model 2\r\n",
        "import tensorflow_hub as hub\r\n",
        "CNN_model_2 = keras.models.load_model(\"model_VGG2.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Loading CNN Model 3\r\n",
        "import tensorflow_hub as hub\r\n",
        "CNN_model_3 = keras.models.load_model(\"model_ns_nd.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------- \r\n",
        "Data set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "## CSV files\r\n",
        "train=pd.read_csv('train.csv') \r\n",
        "valid=pd.read_csv('valid.csv')   \r\n",
        "test=pd.read_csv('test.csv')  \r\n",
        "survey=pd.read_csv('survey.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Image parameters\r\n",
        "batch_size =128\r\n",
        "img_height = 150\r\n",
        "img_width =100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "## train\r\n",
        "list_train = tf.data.Dataset.list_files(str(str(path_train)+\"\\*/*.jp*\"),shuffle=False)\r\n",
        "list_train = list_train.shuffle(len(list_train),reshuffle_each_iteration=False)\r\n",
        "## valid\r\n",
        "list_valid = tf.data.Dataset.list_files(str(str(path_valid)+\"\\*/*.jp*\"),shuffle=False)\r\n",
        "list_valid = list_valid.shuffle(len(list_valid),reshuffle_each_iteration=False)\r\n",
        "## test\r\n",
        "list_test = tf.data.Dataset.list_files(str(str(path_test)+\"\\*/*.jp*\"),shuffle=False)\r\n",
        "list_test = list_test.shuffle(len(list_test),reshuffle_each_iteration=False)\r\n",
        "## survey\r\n",
        "list_survey = tf.data.Dataset.list_files(str(str(path_survey)+\"\\*/*.jp*\"),shuffle=False)\r\n",
        "list_survey = list_survey.shuffle(len(list_survey),reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "# getting the classes names\r\n",
        "class_names = np.array(sorted([item.name for item in path_train.glob('*') if os.path.isdir(item)]))\r\n",
        "def get_label(file_path):\r\n",
        "  # convert the path to a list of path components\r\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\r\n",
        "  # The second to last is the class-directory\r\n",
        "  one_hot = parts[-2] == class_names\r\n",
        "  # Integer encode the label\r\n",
        "  return tf.argmax(one_hot)\r\n",
        "def decode_img(img):\r\n",
        "  # convert the compressed string to a 3D uint8 tensor\r\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\r\n",
        "  # resize the image to the desired size\r\n",
        "  return tf.image.resize(img, [img_height, img_width])\r\n",
        "def process_path(file_path):\r\n",
        "    label = get_label(file_path)\r\n",
        "  # load the raw data from the file as a string\r\n",
        "    img = tf.io.read_file(file_path)\r\n",
        "    img = decode_img(img)\r\n",
        "         \r\n",
        "    return img,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\r\n",
        "AUTOTUNE = tf.data.AUTOTUNE\r\n",
        "train_ds = list_train.map(process_path, num_parallel_calls=AUTOTUNE)\r\n",
        "val_ds = list_valid.map(process_path, num_parallel_calls=AUTOTUNE)\r\n",
        "test_ds = list_test.map(process_path, num_parallel_calls=AUTOTUNE)\r\n",
        "survey_ds = list_survey.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "def configure_for_performance_train(ds):\r\n",
        "  ds = ds.cache()\r\n",
        "  #ds = ds.shuffle(buffer_size=1000,reshuffle_each_iteration=True)\r\n",
        "  #print(ds)\r\n",
        "  ds = ds.batch(batch_size)\r\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\r\n",
        "  return ds\r\n",
        "\r\n",
        "def configure_for_performance_other(ds):\r\n",
        "  ds = ds.cache()\r\n",
        "  # ds = ds.shuffle(buffer_size=1000,reshuffle_each_iteration=False)\r\n",
        "  ds = ds.batch(batch_size)\r\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\r\n",
        "  return ds\r\n",
        "\r\n",
        "train_ds = configure_for_performance_train(train_ds)\r\n",
        "val_ds = configure_for_performance_other(val_ds)\r\n",
        "test_ds = configure_for_performance_other(test_ds)\r\n",
        "survey_ds = configure_for_performance_other(survey_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "## getting the images names and their order \r\n",
        "train_images = [str(obj.numpy()).rsplit(\"\\\\\")[-1][:-1] for obj in list_train]\r\n",
        "valid_images = [str(obj.numpy()).rsplit(\"\\\\\")[-1][:-1] for obj in list_valid]\r\n",
        "test_images = [str(obj.numpy()).rsplit(\"\\\\\")[-1][:-1] for obj in list_test]\r\n",
        "survey_images = [str(obj.numpy()).rsplit(\"_\")[-1][:-1] for obj in list_survey]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reindexing train csv \r\n",
        "train = train.set_index(\"img\")\r\n",
        "train = train.reindex(train_images)\r\n",
        "# reindexing valid csv \r\n",
        "valid = valid.set_index(\"img\")\r\n",
        "valid = valid.reindex(valid_images)\r\n",
        "# reindexing test csv \r\n",
        "test = test.set_index(\"img\")\r\n",
        "test = test.reindex(test_images)\r\n",
        "# reindexing survey csv \r\n",
        "survey = survey.set_index(\"img\")\r\n",
        "survey = survey.reindex(survey_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[['15365.jpg', '15365.jpg'],\n ['40567.jpg', '40567.jpg'],\n ['50757.jpg', '50757.jpg'],\n ['20475.jpg', '20475.jpg'],\n ['9641.jpg', '9641.jpg'],\n ['51189.jpg', '51189.jpg'],\n ['14400.jpg', '14400.jpg'],\n ['31730.jpg', '31730.jpg'],\n ['24676.jpg', '24676.jpg']]"
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checking if the train data sets are in the same order  \r\n",
        "[[a,b] for a,b in zip(train.index[1:10],train_images[1:10])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[['23288.jpg', '23288.jpg'],\n ['4894.jpg', '4894.jpg'],\n ['26250.jpg', '26250.jpg'],\n ['6997.jpg', '6997.jpg'],\n ['26368.jpg', '26368.jpg'],\n ['54068.jpg', '54068.jpg'],\n ['43044.jpg', '43044.jpg'],\n ['51084.jpg', '51084.jpg'],\n ['40610.jpg', '40610.jpg']]"
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checking if the test data sets are in the same order  \r\n",
        "[[a,b] for a,b in zip(test.index[1:10],test_images[1:10])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------\r\n",
        "Clean Titles\r\n",
        "def clean_titles():\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Transforming the book title to a list \r\n",
        "def clean_titles(string):\r\n",
        "    string = re.sub(\"[^a-zA-Z\\s]\",\"\",string).lower().strip()\r\n",
        "    splited=string.split(\" \")\r\n",
        "    if len(splited)>1:\r\n",
        "        return splited\r\n",
        "    else:\r\n",
        "        return \"\"\r\n",
        "# appling to all 4 data frames \r\n",
        "train[\"title\"] = train.book_title.map(clean_titles)\r\n",
        "valid[\"title\"] = valid.book_title.map(clean_titles)\r\n",
        "test[\"title\"] = test.book_title.map(clean_titles)\r\n",
        "survey[\"title\"] = survey.book_title.map(clean_titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "all=pd.concat([test.title,train.title,valid.title,survey.title])\r\n",
        "xtoken = Tokenizer(oov_token=True)\r\n",
        "xtoken.fit_on_texts(all)\r\n",
        "#prepare title\r\n",
        "def prep_title(title):\r\n",
        "    \r\n",
        "    if len(title)>1:\r\n",
        "        x_val = xtoken.texts_to_sequences(title)\r\n",
        "        x_val = pad_sequences(x_val, maxlen=41, padding='pre')\r\n",
        "    else:\r\n",
        "        x_val = np.zeros(41)\r\n",
        "    return x_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stored 'exp_token' (Tokenizer)\n"
          ]
        }
      ],
      "source": [
        "exp_token = xtoken\r\n",
        "%store exp_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "a_test = prep_title(test.title)\r\n",
        "a_train = prep_title(train.title)\r\n",
        "a_valid = prep_title(valid.title)\r\n",
        "a_survey =prep_title(survey.title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           2,   348,    27,     2, 22744])"
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_survey[22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------------------------------\r\n",
        "Naive predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langdetect import detect#remove list that are not in english\r\n",
        "def detect2(s):\r\n",
        "    if len(s)>2:\r\n",
        "        try:\r\n",
        "            d = detect(s)\r\n",
        "        except:\r\n",
        "            d = 'na'\r\n",
        "        return d\r\n",
        "    else:\r\n",
        "        return 'na'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtered_test = test[test.title.map(\" \".join).map(detect2)==\"en\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "%store -r x_test\r\n",
        "%store -r y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_NLP = NLP_model_1.predict(a_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_NLP_2 = NLP_model_2.predict(a_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "['betsy', 'in', 'spite', 'of', 'herself']"
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.title[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,   13, 9523, 1968])"
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.asarray(prep_title(test.title))\r\n",
        "a[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_CNN = CNN_model_1.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_CNN_2 = CNN_model_2.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_CNN_3 = CNN_model_3.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prediction_score(valid,predictions,cnames=class_names):\r\n",
        "    pred = np.argmax(predictions, axis=1)\r\n",
        "    pred2 = np.argsort(predictions,axis=1)[:,-2]\r\n",
        "    pred3 = np.argsort(predictions,axis=1)[:,-3]\r\n",
        "    dict_c = dict(enumerate(cnames))\r\n",
        "    scores=[]\r\n",
        "    for v,p1,p2,p3 in zip(valid,pred,pred2,pred3):\r\n",
        "        score=0\r\n",
        "        top1 = 0\r\n",
        "        top3 = 0\r\n",
        "        if v == p1: score=1\r\n",
        "        elif v == p2: score =0.75\r\n",
        "        elif v == p3: score =0.5\r\n",
        "        if score == 1 : top1 =1\r\n",
        "        if score >=0.5 : top3=1\r\n",
        "        scores.append([dict_c.get(v),score,top1,top3])\r\n",
        "    scores_df = pd.DataFrame(scores,columns=[\"genre\",\"score\",\"top1\",\"top3\"])\r\n",
        "    meanscore =np.round(scores_df[\"score\"].mean(),3)\r\n",
        "    sumtop = np.sum(scores_df[\"top1\"].sum())\r\n",
        "    print(\"The average score is %s\" %meanscore)\r\n",
        "    print(\"Correctly predicted %s / %s\" % (sumtop,len(scores_df)))\r\n",
        "    print(scores_df.groupby(\"genre\").agg({\"score\":\"mean\",\"top1\":[\"sum\",\"mean\"],\"top3\":[\"sum\",\"mean\"],\"genre\":\"count\"}).round(2))\r\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "            Biography       0.55      0.43      0.48       169\n",
            "            Childrens       0.56      0.41      0.48       140\n",
            "              Fantasy       0.48      0.73      0.58       749\n",
            "           Historical       0.38      0.38      0.38       383\n",
            "               Horror       0.49      0.20      0.29       113\n",
            "      Mystery & Crime       0.43      0.44      0.43       341\n",
            "               Poetry       0.47      0.24      0.32        96\n",
            "   Politics & History       0.53      0.41      0.46       189\n",
            "Religion & Philosophy       0.56      0.50      0.53       262\n",
            "              Romance       0.50      0.59      0.54       557\n",
            "      Science Fiction       0.41      0.26      0.32       221\n",
            "       Sequential Art       0.71      0.58      0.64       138\n",
            "          Young Adult       0.42      0.27      0.33       388\n",
            "\n",
            "             accuracy                           0.48      3746\n",
            "            macro avg       0.50      0.42      0.44      3746\n",
            "         weighted avg       0.48      0.48      0.47      3746\n",
            "\n",
            "The average score is 0.643\n",
            "Correctly predicted 1802 / 3746\n",
            "                      score top1       top3       genre\n",
            "                       mean  sum  mean  sum  mean count\n",
            "genre                                                  \n",
            "Biography              0.53   72  0.43  101  0.60   169\n",
            "Childrens              0.56   58  0.41   90  0.64   140\n",
            "Fantasy                0.87  549  0.73  709  0.95   749\n",
            "Historical             0.59  146  0.38  276  0.72   383\n",
            "Horror                 0.27   23  0.20   34  0.30   113\n",
            "Mystery & Crime        0.59  149  0.44  228  0.67   341\n",
            "Poetry                 0.29   23  0.24   32  0.33    96\n",
            "Politics & History     0.51   78  0.41  106  0.56   189\n",
            "Religion & Philosophy  0.62  132  0.50  181  0.69   262\n",
            "Romance                0.78  328  0.59  487  0.87   557\n",
            "Science Fiction        0.44   58  0.26  119  0.54   221\n",
            "Sequential Art         0.71   80  0.58  106  0.77   138\n",
            "Young Adult            0.53  106  0.27  269  0.69   388\n"
          ]
        }
      ],
      "source": [
        "predictions = predictions_NLP +predictions_NLP_2+predictions_CNN +predictions_CNN_2+predictions_CNN_3\r\n",
        "predicted_classes = np.argmax(predictions, axis=1)\r\n",
        "#oclasses = [[c.numpy() for c in object[1]]for object in test_ds]\r\n",
        "#original_classes = np.concatenate(oclasses).ravel()\r\n",
        "original_classes=test.main_label.map(list(class_names).index) #np.argmax(y_test,axis=1) #\r\n",
        "print(classification_report(original_classes, predicted_classes, target_names=class_names,zero_division=0))\r\n",
        "prediction_score(original_classes,predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------\r\n",
        "Complex fusion of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models =list()\r\n",
        "all_models=[NLP_model_1,NLP_model_2,CNN_model_1,CNN_model_2,CNN_model_3]\r\n",
        "NLP_models=[NLP_model_1,NLP_model_2]\r\n",
        "CNN_models=[CNN_model_1,CNN_model_2,CNN_model_3]\r\n",
        "mix_models=[NLP_model_1,CNN_model_1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "(None, 41)"
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NLP_model_1.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define stacked model from multiple member input models\r\n",
        "def define_stacked_model(members):\r\n",
        "\t# update all layers in all models to not be trainable\r\n",
        "\tfor i in range(len(members)):\r\n",
        "\t\tmodel = members[i]\r\n",
        "\t\tfor layer in model.layers:\r\n",
        "\t\t\t# make not trainable\r\n",
        "\t\t\tlayer.trainable = False\r\n",
        "\t\t\t# rename to avoid 'unique layer name' issue\r\n",
        "\t\t\tlayer._name = 'ensemble_' + str(i+1) + '_' + layer.name\r\n",
        "\t# define multi-headed input\r\n",
        "\t#inputA = Input(shape=(None, 41))\r\n",
        "\t#inputB = Input(shape=(None, 150, 100, 3))\r\n",
        "\t#members[0](inputA)\r\n",
        "\t#members[1](inputA)\r\n",
        "\t#members[2](inputB)\r\n",
        "\t#members[3](inputB)\r\n",
        "\t#members[4](inputB)\r\n",
        "\tensemble_visible = [model.input for model in members]\r\n",
        "\t# concatenate merge output from each model\r\n",
        "\tensemble_outputs = [model.output for model in members]\r\n",
        "\tmerge = concatenate(ensemble_outputs)\r\n",
        "\thidden = Dense(65, activation='relu')(merge)\r\n",
        "\toutput = Dense(13, activation='softmax')(hidden)\r\n",
        "\tmodel = Model(inputs=ensemble_visible, outputs=output)\r\n",
        "\t# plot graph of ensemble\r\n",
        "\tplot_model(model, show_shapes=True, to_file='model_graph.png')\r\n",
        "\t# compile\r\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit a stacked model\r\n",
        "def fit_stacked_model(model, inputX, inputy):\r\n",
        "\t# prepare input data\r\n",
        "\tX = [inputX for _ in range(len(model.input))]\r\n",
        "\tprint(np.shape(X))\r\n",
        "\t# encode output data\r\n",
        "\tinputy_enc = to_categorical(inputy)\r\n",
        "\t# fit model\r\n",
        "\tmodel.fit(X, inputy_enc, epochs=10, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_stacked_model(model, inputX):\r\n",
        "\t# prepare input data\r\n",
        "\tX = [inputX for _ in range(len(model.input))]\r\n",
        "\t# make prediction\r\n",
        "\treturn model.predict(X, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\r\n",
        "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz/bin/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\r\n",
        "from tensorflow.keras.layers import concatenate\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "stacked_model = define_stacked_model(all_models)\r\n",
        "NLP_stacked_model = define_stacked_model(NLP_models)\r\n",
        "CNN_stacked_model = define_stacked_model(CNN_models)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "original_train_classes=train.main_label.map(list(class_names).index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = [a_train,a_train,train_ds,train_ds,train_ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\r\n",
        "Y = np.asarray(original_train_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y = to_categorical(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[<KerasTensor: shape=(None, 41) dtype=float32 (created by layer 'embedding_2_input')>,\n <KerasTensor: shape=(None, 41) dtype=float32 (created by layer 'embedding_3_input')>,\n <KerasTensor: shape=(None, 150, 100, 3) dtype=float32 (created by layer 'rescaling_1_input')>,\n <KerasTensor: shape=(None, 150, 100, 3) dtype=float32 (created by layer 'rescaling_3_input')>,\n <KerasTensor: shape=(None, 150, 100, 3) dtype=float32 (created by layer 'rescaling_6_input')>]"
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stacked_model.input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fit_stacked_model(stacked_model,X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "990/990 [==============================] - 11s 5ms/step - loss: 1.5243 - accuracy: 0.5892\n",
            "Epoch 2/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9327 - accuracy: 0.7116\n",
            "Epoch 3/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9297 - accuracy: 0.7139\n",
            "Epoch 4/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9046 - accuracy: 0.7181\n",
            "Epoch 5/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9157 - accuracy: 0.7175\n",
            "Epoch 6/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9167 - accuracy: 0.7158\n",
            "Epoch 7/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9126 - accuracy: 0.7169\n",
            "Epoch 8/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9128 - accuracy: 0.7153\n",
            "Epoch 9/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9252 - accuracy: 0.7144\n",
            "Epoch 10/10\n",
            "990/990 [==============================] - 5s 5ms/step - loss: 0.9160 - accuracy: 0.7170\n"
          ]
        },
        {
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x15cab680a30>"
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NLP_stacked_model.fit([a_train,a_train],Y,epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_stacked_model_CNN(members):\r\n",
        "# update all layers in all models to not be trainable\r\n",
        " for i in range(len(members)):\r\n",
        "  model = members[i]\r\n",
        "  for layer in model.layers:\r\n",
        "   # make not trainable\r\n",
        "   layer.trainable = False\r\n",
        "# rename to avoid 'unique layer name' issue\r\n",
        "   layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\r\n",
        "\r\n",
        "#inputB = Input(shape=(None, 150, 100, 3))\r\n",
        " #inputA = Input(shape=(150,100,3,))\r\n",
        "# members[0](inputA)\r\n",
        "# members[1](inputA)\r\n",
        "# members[2](inputA)\r\n",
        "#members[2](inputB)\r\n",
        "#members[3](inputB)\r\n",
        "#members[4](inputB)\r\n",
        " ensemble_visible = [model.input for model in members]\r\n",
        "# concatenate merge output from each model\r\n",
        "#ensemble_outputs = [model.output for model in members]\r\n",
        " merge = concatenate(axis=1)([members[0].output,members[1].output,members[2].output])\r\n",
        " hidden = Dense(65, activation='relu')(merge)\r\n",
        " S_output = Dense(13, activation='softmax')(hidden)\r\n",
        " model = Model(inputs=ensemble_visible, outputs=S_output)\r\n",
        "# plot graph of ensemble\r\n",
        " plot_model(model, show_shapes=True, to_file='model_graph.png')\r\n",
        "# compile\r\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        " return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "(None, 150, 100, 3)"
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN_model_1.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=[train,train_ds]\r\n",
        "\r\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "stacked_mix_models = define_stacked_model(mix_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "CNN_stacked_model = define_stacked_model(CNN_models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.frame.DataFrame'>\", \"<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\"}), <class 'numpy.ndarray'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-241-ee54d14dd909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstacked_mix_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    959\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \"input: {}, {}\".format(\n",
            "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.frame.DataFrame'>\", \"<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\"}), <class 'numpy.ndarray'>"
          ]
        }
      ],
      "source": [
        "stacked_mix_models.fit(X,Y,epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------\r\n",
        "Other try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import dstack\r\n",
        "def stacked_dataset(members, inputX):\r\n",
        "\tstackX = None\r\n",
        "\tfor model in members:\r\n",
        "\t\t# make prediction\r\n",
        "\t\tyhat = model.predict(inputX, verbose=0)\r\n",
        "\t\t# stack predictions into [rows, members, probabilities]\r\n",
        "\t\tif stackX is None:\r\n",
        "\t\t\tstackX = yhat\r\n",
        "\t\telse:\r\n",
        "\t\t\tstackX = dstack((stackX, yhat))\r\n",
        "\t# flatten predictions to [rows, members x probabilities]\r\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\r\n",
        "\treturn stackX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_NLP = stacked_dataset(NLP_models,a_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_NLP_valid = stacked_dataset(NLP_models,a_valid)\r\n",
        "stack_NLP_test = stacked_dataset(NLP_models,a_test)\r\n",
        "stack_NLP_survey = stacked_dataset(NLP_models,a_survey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_CNN = stacked_dataset(CNN_models,train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_CNN_valid = stacked_dataset(CNN_models,val_ds)\r\n",
        "stack_CNN_test = stacked_dataset(CNN_models,test_ds)\r\n",
        "stack_CNN_survey = stacked_dataset(CNN_models,survey_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('cnn_predict.pickle', 'wb') as output:\r\n",
        "    pickle.dump(stack_CNN, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('stack_CNN_valid.pickle', 'wb') as output:\r\n",
        "    pickle.dump(stack_CNN_valid, output)\r\n",
        "with open('stack_CNN_test.pickle', 'wb') as output:\r\n",
        "    pickle.dump(stack_CNN_test, output)\r\n",
        "with open('stack_CNN_survey.pickle', 'wb') as output:\r\n",
        "    pickle.dump(stack_CNN_survey, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "#merging both data sets\r\n",
        "train_predict = np.concatenate((stack_NLP,stack_CNN),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_predict = np.concatenate((stack_NLP_valid,stack_CNN_valid),axis=1)\r\n",
        "test_predict = np.concatenate((stack_NLP_test,stack_CNN_test),axis=1)\r\n",
        "survey_predict = np.concatenate((stack_NLP_survey,stack_CNN_survey),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('train_predict.pickle', 'wb') as output:\r\n",
        "    pickle.dump(train_predict, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.regularizers import l2\r\n",
        "model_stacked = tf.keras.Sequential([\r\n",
        "   layers.Dropout(0.6), \r\n",
        "   layers.Dense(13, activation='softmax', activity_regularizer=l2(0.1))\r\n",
        "])\r\n",
        "model_stacked.compile(\r\n",
        "   \r\n",
        "    optimizer=tf.keras.optimizers.Adam(\r\n",
        "        learning_rate=0.0002,\r\n",
        "        \r\n",
        "    ),\r\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "ES= callbacks.EarlyStopping(monitor='val_accuracy', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_train = np.asarray(original_train_classes)\r\n",
        "Y_valid = np.asarray(valid.main_label.map(list(class_names).index))\r\n",
        "Y_test = np.asarray(test.main_label.map(list(class_names).index))\r\n",
        "Y_survey = np.asarray(survey.main_label.map(list(class_names).index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "990/990 [==============================] - 1s 927us/step - loss: 1.0533 - accuracy: 0.6839 - val_loss: 1.6301 - val_accuracy: 0.4980\n",
            "Epoch 2/45\n",
            "990/990 [==============================] - 1s 878us/step - loss: 1.0569 - accuracy: 0.6831 - val_loss: 1.6302 - val_accuracy: 0.4977\n",
            "Epoch 3/45\n",
            "990/990 [==============================] - 1s 886us/step - loss: 1.0401 - accuracy: 0.6892 - val_loss: 1.6308 - val_accuracy: 0.4984\n",
            "Epoch 4/45\n",
            "990/990 [==============================] - 1s 903us/step - loss: 1.0580 - accuracy: 0.6857 - val_loss: 1.6312 - val_accuracy: 0.4976\n",
            "Epoch 5/45\n",
            "990/990 [==============================] - 1s 985us/step - loss: 1.0556 - accuracy: 0.6859 - val_loss: 1.6316 - val_accuracy: 0.4985\n",
            "Epoch 6/45\n",
            "990/990 [==============================] - 1s 884us/step - loss: 1.0531 - accuracy: 0.6862 - val_loss: 1.6318 - val_accuracy: 0.4985\n",
            "Epoch 7/45\n",
            "990/990 [==============================] - 1s 880us/step - loss: 1.0396 - accuracy: 0.6898 - val_loss: 1.6323 - val_accuracy: 0.4984\n"
          ]
        }
      ],
      "source": [
        "history_stacked = model_stacked.fit(train_predict,Y_train,validation_data=(valid_predict, Y_valid),callbacks=[ES],epochs=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model_stacked.predict(test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "            Biography       0.51      0.43      0.47       169\n",
            "            Childrens       0.62      0.42      0.50       140\n",
            "              Fantasy       0.52      0.69      0.60       749\n",
            "           Historical       0.34      0.43      0.38       383\n",
            "               Horror       0.53      0.18      0.26       113\n",
            "      Mystery & Crime       0.45      0.46      0.46       341\n",
            "               Poetry       0.65      0.23      0.34        96\n",
            "   Politics & History       0.61      0.38      0.47       189\n",
            "Religion & Philosophy       0.49      0.51      0.50       262\n",
            "              Romance       0.54      0.58      0.56       557\n",
            "      Science Fiction       0.38      0.26      0.31       221\n",
            "       Sequential Art       0.76      0.63      0.69       138\n",
            "          Young Adult       0.38      0.35      0.36       388\n",
            "\n",
            "             accuracy                           0.49      3746\n",
            "            macro avg       0.52      0.43      0.45      3746\n",
            "         weighted avg       0.49      0.49      0.48      3746\n",
            "\n",
            "The average score is 0.656\n",
            "Correctly predicted 1824 / 3746\n",
            "                      score top1       top3       genre\n",
            "                       mean  sum  mean  sum  mean count\n",
            "genre                                                  \n",
            "Biography              0.54   72  0.43  101  0.60   169\n",
            "Childrens              0.54   59  0.42   86  0.61   140\n",
            "Fantasy                0.86  518  0.69  709  0.95   749\n",
            "Historical             0.66  166  0.43  300  0.78   383\n",
            "Horror                 0.30   20  0.18   42  0.37   113\n",
            "Mystery & Crime        0.59  158  0.46  222  0.65   341\n",
            "Poetry                 0.32   22  0.23   36  0.38    96\n",
            "Politics & History     0.52   71  0.38  113  0.60   189\n",
            "Religion & Philosophy  0.64  133  0.51  186  0.71   262\n",
            "Romance                0.76  325  0.58  472  0.85   557\n",
            "Science Fiction        0.48   57  0.26  133  0.60   221\n",
            "Sequential Art         0.72   87  0.63  105  0.76   138\n",
            "Young Adult            0.61  136  0.35  291  0.75   388\n"
          ]
        }
      ],
      "source": [
        "predicted_classes = np.argmax(predictions, axis=1)\r\n",
        "original_classes=test.main_label.map(list(class_names).index) \r\n",
        "print(classification_report(original_classes, predicted_classes, target_names=class_names,zero_division=0))\r\n",
        "prediction_score(original_classes,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "            Biography       0.75      0.60      0.67         5\n",
            "            Childrens       1.00      0.60      0.75         5\n",
            "              Fantasy       0.27      0.80      0.40         5\n",
            "           Historical       0.33      0.60      0.43         5\n",
            "               Horror       0.00      0.00      0.00         5\n",
            "      Mystery & Crime       0.50      0.20      0.29         5\n",
            "               Poetry       0.50      0.20      0.29         5\n",
            "   Politics & History       1.00      0.20      0.33         5\n",
            "Religion & Philosophy       0.44      0.80      0.57         5\n",
            "              Romance       0.62      1.00      0.77         5\n",
            "      Science Fiction       0.50      0.40      0.44         5\n",
            "       Sequential Art       1.00      0.80      0.89         5\n",
            "          Young Adult       0.67      0.40      0.50         5\n",
            "\n",
            "             accuracy                           0.51        65\n",
            "            macro avg       0.58      0.51      0.49        65\n",
            "         weighted avg       0.58      0.51      0.49        65\n",
            "\n",
            "The average score is 0.619\n",
            "Correctly predicted 33 / 65\n",
            "                      score top1      top3      genre\n",
            "                       mean  sum mean  sum mean count\n",
            "genre                                                \n",
            "Biography              0.60    3  0.6    3  0.6     5\n",
            "Childrens              0.60    3  0.6    3  0.6     5\n",
            "Fantasy                0.80    4  0.8    4  0.8     5\n",
            "Historical             0.75    3  0.6    4  0.8     5\n",
            "Horror                 0.10    0  0.0    1  0.2     5\n",
            "Mystery & Crime        0.60    1  0.2    4  0.8     5\n",
            "Poetry                 0.30    1  0.2    2  0.4     5\n",
            "Politics & History     0.30    1  0.2    2  0.4     5\n",
            "Religion & Philosophy  0.80    4  0.8    4  0.8     5\n",
            "Romance                1.00    5  1.0    5  1.0     5\n",
            "Science Fiction        0.55    2  0.4    3  0.6     5\n",
            "Sequential Art         0.80    4  0.8    4  0.8     5\n",
            "Young Adult            0.85    2  0.4    5  1.0     5\n"
          ]
        }
      ],
      "source": [
        "survey_predictions = model_stacked.predict(survey_predict)\r\n",
        "predicted_classes = np.argmax(survey_predictions, axis=1)\r\n",
        "original_classes=survey.main_label.map(list(class_names).index) \r\n",
        "print(classification_report(original_classes, predicted_classes, target_names=class_names,zero_division=0))\r\n",
        "prediction_score(original_classes,survey_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\istra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12], y=[ 7  9  4 ...  8 10  7] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import class_weight\r\n",
        "\r\n",
        "   \r\n",
        "\r\n",
        "#cw = class_weight.compute_class_weight('balanced',np.unique(books['main_label']), books['main_label']),\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "cw = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\r\n",
        "cw = dict(enumerate(cw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "array([ 7,  9,  4, ...,  8, 10,  7], dtype=int64)"
          },
          "execution_count": 471,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_stacked_w = tf.keras.Sequential([\r\n",
        "    \r\n",
        "    layers.Dropout(0.6),\r\n",
        "   layers.Dense(13, activation='softmax', activity_regularizer=l2(0.25))\r\n",
        "])\r\n",
        "model_stacked_w.compile(\r\n",
        "   \r\n",
        "    optimizer=tf.keras.optimizers.Adam(\r\n",
        "        learning_rate=0.002,\r\n",
        "        \r\n",
        "    ),\r\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "ES= callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/45\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 2.0202 - accuracy: 0.4528 - val_loss: 1.8694 - val_accuracy: 0.4760\n",
            "Epoch 2/45\n",
            "990/990 [==============================] - 1s 921us/step - loss: 1.3038 - accuracy: 0.6638 - val_loss: 1.7842 - val_accuracy: 0.4736\n",
            "Epoch 3/45\n",
            "990/990 [==============================] - 1s 922us/step - loss: 1.2173 - accuracy: 0.6719 - val_loss: 1.7677 - val_accuracy: 0.4740\n",
            "Epoch 4/45\n",
            "990/990 [==============================] - 1s 887us/step - loss: 1.1820 - accuracy: 0.6676 - val_loss: 1.7713 - val_accuracy: 0.4683\n",
            "Epoch 5/45\n",
            "990/990 [==============================] - 1s 889us/step - loss: 1.1778 - accuracy: 0.6679 - val_loss: 1.7573 - val_accuracy: 0.4751\n",
            "Epoch 6/45\n",
            "990/990 [==============================] - 1s 920us/step - loss: 1.1509 - accuracy: 0.6737 - val_loss: 1.7670 - val_accuracy: 0.4744\n"
          ]
        }
      ],
      "source": [
        "history_stacked_weighted = model_stacked_w.fit(train_predict,Y_train,validation_data=(valid_predict, Y_valid),callbacks=[ES],epochs=45,class_weight=cw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "            Biography       0.43      0.60      0.50         5\n",
            "            Childrens       1.00      0.60      0.75         5\n",
            "              Fantasy       0.50      0.80      0.62         5\n",
            "           Historical       0.38      0.60      0.46         5\n",
            "               Horror       0.25      0.20      0.22         5\n",
            "      Mystery & Crime       0.50      0.20      0.29         5\n",
            "               Poetry       0.40      0.40      0.40         5\n",
            "   Politics & History       1.00      0.20      0.33         5\n",
            "Religion & Philosophy       0.57      0.80      0.67         5\n",
            "              Romance       0.57      0.80      0.67         5\n",
            "      Science Fiction       0.60      0.60      0.60         5\n",
            "       Sequential Art       1.00      0.80      0.89         5\n",
            "          Young Adult       0.75      0.60      0.67         5\n",
            "\n",
            "             accuracy                           0.55        65\n",
            "            macro avg       0.61      0.55      0.54        65\n",
            "         weighted avg       0.61      0.55      0.54        65\n",
            "\n",
            "The average score is 0.696\n",
            "Correctly predicted 36 / 65\n",
            "                      score top1      top3      genre\n",
            "                       mean  sum mean  sum mean count\n",
            "genre                                                \n",
            "Biography              0.70    3  0.6    4  0.8     5\n",
            "Childrens              0.75    3  0.6    4  0.8     5\n",
            "Fantasy                0.80    4  0.8    4  0.8     5\n",
            "Historical             0.75    3  0.6    4  0.8     5\n",
            "Horror                 0.40    1  0.2    3  0.6     5\n",
            "Mystery & Crime        0.50    1  0.2    4  0.8     5\n",
            "Poetry                 0.65    2  0.4    4  0.8     5\n",
            "Politics & History     0.35    1  0.2    2  0.4     5\n",
            "Religion & Philosophy  0.80    4  0.8    4  0.8     5\n",
            "Romance                0.95    4  0.8    5  1.0     5\n",
            "Science Fiction        0.60    3  0.6    3  0.6     5\n",
            "Sequential Art         0.90    4  0.8    5  1.0     5\n",
            "Young Adult            0.90    3  0.6    5  1.0     5\n"
          ]
        }
      ],
      "source": [
        "survey_predictions = model_stacked_w.predict(survey_predict)\r\n",
        "predicted_classes = np.argmax(survey_predictions, axis=1)\r\n",
        "original_classes=survey.main_label.map(list(class_names).index) \r\n",
        "print(classification_report(original_classes, predicted_classes, target_names=class_names,zero_division=0))\r\n",
        "prediction_score(original_classes,survey_predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPqHD/t3+nujxAIJkOVUZ3F",
      "include_colab_link": true,
      "mount_file_id": "1WKJzk5XTZu4K7DG73H-TDhqI-X60AbqS",
      "name": "ML_TPG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit (windows store)",
      "name": "python388jvsc74a57bd0dd3bd3722d55832e94689fac739e2c4b496bf0eb12989a7898367024420b8016"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "metadata": {
      "interpreter": {
        "hash": "dd3bd3722d55832e94689fac739e2c4b496bf0eb12989a7898367024420b8016"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}