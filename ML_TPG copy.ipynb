{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML_TPG.ipynb",
      "provenance": [],
      "mount_file_id": "1WKJzk5XTZu4K7DG73H-TDhqI-X60AbqS",
      "authorship_tag": "ABX9TyPqHD/t3+nujxAIJkOVUZ3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "dd3bd3722d55832e94689fac739e2c4b496bf0eb12989a7898367024420b8016"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Istrate/80629_Project/blob/main/ML_TPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smTmZO8eu5Uz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import copy\n",
        "from random import seed\n",
        "from random import random\n",
        "import matplotlib.pyplot as plt  # import matplotlib for plotting and visualization\n",
        "import matplotlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.utils import class_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqpsrIvlGB6H"
      },
      "source": [
        "Checking our images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6i1z4RUGBqu",
        "outputId": "43e3f0be-ed48-474a-d359-2cab26a24c0c"
      },
      "source": [
        "## images path\n",
        "path_s = r\"C:\\Users\\istra\\Google Drive\\Cours HEC\\Maitrise\\Semestre 2\\Machine_Learning\\TP GROUPE\\book_covers\"\n",
        "path = pathlib.Path(path_s)\n",
        "image_count=len(list(path.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OoeRdZIHJCH"
      },
      "source": [
        "Checking a childrens book"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "6ygTMZJoHNUw",
        "outputId": "ca932d40-6bd3-425c-d74d-bd13f7473e0a"
      },
      "source": [
        "children = list(path.glob('Childrens/*'))\n",
        "PIL.Image.open(str(children[12]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kutRh9pHroI"
      },
      "source": [
        "Creating a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeP6pILOHuA9",
        "outputId": "bae9bf97-e7e3-48cc-8212-04c5b4278258"
      },
      "source": [
        "batch_size =32\n",
        "img_height = 150\n",
        "img_width =100\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(path_s+\"\\*/*.jp*\"),shuffle=False)\n",
        "list_ds = list_ds.shuffle(image_count,reshuffle_each_iteration=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = np.array(sorted([item.name for item in path.glob('*') if os.path.isdir(item)]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_size = int(image_count*0.2)\n",
        "train_ds = list_ds.skip(val_size)\n",
        "val_ds = list_ds.take(val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
        "print(tf.data.experimental.cardinality(val_ds).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  one_hot = parts[-2] == class_names\n",
        "  # Integer encode the label\n",
        "  return tf.argmax(one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # resize the image to the desired size\n",
        "  return tf.image.resize(img, [img_height, img_width])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_path(file_path):\n",
        "    label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    #if tf.io.is_jpeg(file_path):\n",
        "     #   img = decode_img(img)\n",
        "   # else:\n",
        "     #   print(\"error : %s is not a jpg\" %file_path)\n",
        "    return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for image, label in train_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())\n",
        "  plt.imshow(image.numpy().astype(\"uint8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXG0mUWEORA6"
      },
      "source": [
        "Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "num_classes=12\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3,strides=1, activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Conv2D(32, 3,strides=1,  activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Conv2D(64, 3,strides=1,  activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(256, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.0001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=True, \n",
        "    name='RMSprop'\n",
        "),\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(val_ds)\n",
        "predicted_classes = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "classes = list()\n",
        "vclasses = [[c.numpy() for c in object[1]]for object in val_ds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_classes = np.concatenate(classes).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      Childrens       0.06      0.02      0.03       228\n",
            "       Classics       0.10      0.06      0.08       570\n",
            "       Cultural       0.00      0.00      0.00       269\n",
            "        Fantasy       0.23      0.67      0.34      1506\n",
            "     Historical       0.08      0.08      0.08       637\n",
            "        History       0.00      0.00      0.00       268\n",
            "         Horror       0.13      0.01      0.02       227\n",
            "        Mystery       0.08      0.04      0.05       497\n",
            "        Romance       0.14      0.08      0.10       918\n",
            "Science Fiction       0.00      0.00      0.00       424\n",
            " Sequential Art       0.09      0.02      0.04       304\n",
            "    Young Adult       0.11      0.05      0.07       794\n",
            "\n",
            "       accuracy                           0.19      6642\n",
            "      macro avg       0.08      0.09      0.07      6642\n",
            "   weighted avg       0.12      0.19      0.12      6642\n",
            "\n",
            "C:\\Users\\istra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\istra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\istra\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(validation_classes, predicted_classes, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}